#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è®­ç»ƒæŒ‡æ ‡ API çš„ç®€å•è„šæœ¬
"""
import os
import json
import sys

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥
current_dir = os.path.dirname(os.path.abspath(__file__))
prediction_dir = os.path.dirname(current_dir)
sys.path.insert(0, prediction_dir)

def test_metrics_file_logic():
    """æµ‹è¯•æŒ‡æ ‡æ–‡ä»¶è¯»å–é€»è¾‘"""
    print("=== æµ‹è¯•è®­ç»ƒæŒ‡æ ‡æ–‡ä»¶è¯»å–é€»è¾‘ ===")
    
    # æ¨¡æ‹Ÿ PROVINCES åˆ—è¡¨
    PROVINCES = ["åŒ—äº¬å¸‚", "ä¸Šæµ·å¸‚", "å¹¿ä¸œçœ"]
    
    models_dir = os.path.join(prediction_dir, 'models')
    print(f"æ¨¡å‹ç›®å½•: {models_dir}")
    
    for province in PROVINCES:
        metrics_file = os.path.join(models_dir, f"{province}_training_metrics.json")
        print(f"\næ£€æŸ¥çœä»½: {province}")
        print(f"æŒ‡æ ‡æ–‡ä»¶è·¯å¾„: {metrics_file}")
        
        if os.path.exists(metrics_file):
            try:
                with open(metrics_file, 'r', encoding='utf-8') as mf:
                    metrics = json.load(mf)
                print(f"âœ… æˆåŠŸè¯»å–æŒ‡æ ‡æ–‡ä»¶")
                print(f"   - çœä»½: {metrics.get('province', 'N/A')}")
                print(f"   - ä¿å­˜æ—¶é—´: {metrics.get('saved_at', 'N/A')}")
                print(f"   - è®­ç»ƒè½®æ•°: {metrics.get('num_epochs', 'N/A')}")
                if 'metrics' in metrics:
                    train_loss = metrics['metrics'].get('train_loss', [])
                    print(f"   - è®­ç»ƒæŸå¤±æ•°æ®ç‚¹: {len(train_loss)} ä¸ª")
                    if train_loss:
                        print(f"   - æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_loss[-1]:.4f}")
            except Exception as e:
                print(f"âŒ è¯»å–æŒ‡æ ‡æ–‡ä»¶å¤±è´¥: {e}")
        else:
            print(f"âŒ æŒ‡æ ‡æ–‡ä»¶ä¸å­˜åœ¨")
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶
            model_pth = os.path.join(models_dir, f"{province}_seq2seq_gdp_model.pth")
            model_onnx = os.path.join(models_dir, f"{province}_seq2seq_gdp_model.onnx")
            if os.path.exists(model_pth) or os.path.exists(model_onnx):
                print(f"   ğŸ’¡ ä½†å­˜åœ¨æ¨¡å‹æ–‡ä»¶ï¼Œéœ€è¦é‡æ–°è®­ç»ƒä»¥ç”ŸæˆæŒ‡æ ‡")

def create_sample_metrics_file():
    """åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æŒ‡æ ‡æ–‡ä»¶ç”¨äºæµ‹è¯•"""
    print("\n=== åˆ›å»ºç¤ºä¾‹æŒ‡æ ‡æ–‡ä»¶ ===")
    
    models_dir = os.path.join(prediction_dir, 'models')
    os.makedirs(models_dir, exist_ok=True)
    
    sample_metrics = {
        'province': 'æµ‹è¯•çœä»½',
        'saved_at': '2025-12-07T10:30:00',
        'num_epochs': 5,
        'hyperparams': {
            'input_feature_size': 4,
            'hidden_size': 8,
            'num_layers': 2,
            'predict_steps': 2,
            'window_size': 6,
            'batch_size': 1
        },
        'metrics': {
            'train_loss': [0.5, 0.4, 0.3, 0.25, 0.2],
            'train_mae': [0.3, 0.25, 0.2, 0.18, 0.15],
            'train_mse': [0.5, 0.4, 0.3, 0.25, 0.2],
            'train_mape': [15.0, 12.0, 10.0, 9.0, 8.0],
            'test_loss': [0.52, 0.42, 0.32, 0.27, 0.22],
            'test_mae': [0.32, 0.27, 0.22, 0.20, 0.17],
            'test_mse': [0.52, 0.42, 0.32, 0.27, 0.22],
            'test_mape': [16.0, 13.0, 11.0, 10.0, 9.0]
        }
    }
    
    sample_file = os.path.join(models_dir, "æµ‹è¯•çœä»½_training_metrics.json")
    try:
        with open(sample_file, 'w', encoding='utf-8') as f:
            json.dump(sample_metrics, f, ensure_ascii=False, indent=2)
        print(f"âœ… ç¤ºä¾‹æŒ‡æ ‡æ–‡ä»¶å·²åˆ›å»º: {sample_file}")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºç¤ºä¾‹æ–‡ä»¶å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    test_metrics_file_logic()
    create_sample_metrics_file()
    print("\n=== æµ‹è¯•å®Œæˆ ===")
    print("ğŸ’¡ æç¤º:")
    print("1. å¦‚æœæƒ³è¦çœŸå®çš„æŒ‡æ ‡æ–‡ä»¶ï¼Œéœ€è¦è¿è¡Œ train.py é‡æ–°è®­ç»ƒæ¨¡å‹")
    print("2. API è·¯ç”± /api/gdp/metrics/<province> å·²æ·»åŠ åˆ° app.py")
    print("3. å¯åŠ¨æœåŠ¡å™¨åå¯ä»¥è®¿é—®: http://localhost:5000/api/gdp/metrics/æµ‹è¯•çœä»½")